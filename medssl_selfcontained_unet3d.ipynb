{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6893e7e8",
   "metadata": {},
   "source": [
    "# Self‑Contained 3D Segmentation Notebook (U‑Net‑style, Deep Supervision)\n",
    "This notebook is **self-contained**: it defines the model, dataloaders, losses, training loop, sliding‑window inference, and simple evaluation **inside** the notebook.\n",
    "\n",
    "### What it covers\n",
    "- Reads **nnU‑Net v2** plans to mirror *spacing* and *patch size* (for fair comparison).\n",
    "- Minimal **CT/MRI normalization** and **resampling to target spacing** via SimpleITK.\n",
    "- A **Residual U‑Net 3D** with **deep supervision**.\n",
    "- **Dice + Cross‑Entropy** loss, AMP, checkpointing by **val Dice**.\n",
    "- A simple **sliding‑window** predictor (with optional test‑time mirroring).\n",
    "\n",
    "> **Where to put it:** save/run in your WSL repo folder (`~/projects/medssl_from_scratch`) or anywhere you like. Just ensure the paths below are correct.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd458d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Config: edit these for Heart vs Spleen, paths, and training knobs ---\n",
    "DATA_ROOT = \"/home/htetaung/data\"            # where MSD + nnU-Net folders live\n",
    "TASK      = \"Task02_Heart\"                   # or \"Task09_Spleen\"\n",
    "DS_ID     = 2 if TASK == \"Task02_Heart\" else 9\n",
    "NAME      = \"Heart\" if DS_ID == 2 else \"Spleen\"\n",
    "FOLD      = 0\n",
    "IN_CHANNELS = 1\n",
    "NUM_CLASSES = 2                              # bg + structure\n",
    "MAX_EPOCHS = 50\n",
    "BATCH_SIZE = 2\n",
    "PATCH      = (96, 96, 96)                    # will print nnU-Net patch below; you can copy it if VRAM allows\n",
    "NUM_WORKERS = 4\n",
    "AMP = True\n",
    "OUT_DIR = f\"./runs_selfcontained/{TASK}_unet_resdeep_fold{FOLD}\"\n",
    "LIST_TRAIN = f\"./lists/{TASK}_train_fold{FOLD}.txt\"   # reuse nnU-Net split -> created earlier\n",
    "LIST_VAL   = f\"./lists/{TASK}_val_fold{FOLD}.txt\"\n",
    "\n",
    "# modality for normalization: \"CT\" or \"MRI\"\n",
    "MODALITY = \"MRI\" if TASK == \"Task02_Heart\" else \"CT\"\n",
    "\n",
    "# test-time augmentation (mirror flips over axes)\n",
    "TTA_MIRROR = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82459b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Imports & sanity ---\n",
    "import os, json, math, time, random, shutil, csv\n",
    "from pathlib import Path\n",
    "from typing import Tuple, List\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "print(\"Torch:\", torch.__version__)\n",
    "print(\"CUDA:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbc2caa",
   "metadata": {},
   "source": [
    "## Read nnU‑Net plans (spacing & patch size)\n",
    "Use these values for fair comparisons. If you have enough VRAM, set `PATCH` to the printed patch size.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51ec363",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_nnunet_cfg(ds_id, name, data_root=DATA_ROOT):\n",
    "    base = f\"{data_root}/nnunet_preprocessed/Dataset0{ds_id:02d}_{name}\"\n",
    "    with open(f\"{base}/nnUNetPlans.json\") as f:\n",
    "        plans = json.load(f)\n",
    "    cfg = plans.get(\"configurations\", {}).get(\"3d_fullres\", {})\n",
    "    spacing = (cfg.get(\"spacing\") or cfg.get(\"resampling_target_spacing\") or\n",
    "               plans.get(\"target_spacing\") or plans.get(\"spacing\"))\n",
    "    patch_size = tuple(cfg.get(\"patch_size\") or ())\n",
    "    batch_size = cfg.get(\"batch_size\")\n",
    "    return spacing, patch_size, batch_size\n",
    "\n",
    "spacing, nn_patch, nn_bs = read_nnunet_cfg(DS_ID, NAME)\n",
    "print(f\"Dataset {DS_ID} {NAME} -> spacing={spacing}, patch_size={nn_patch}, batch_size={nn_bs}\")\n",
    "print(f\"Using PATCH (for this notebook) =\", PATCH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145ee19b",
   "metadata": {},
   "source": [
    "## Dataset & preprocessing\n",
    "- We read list files of `image_path,label_path`.\n",
    "- **Resample** each image/label to the **nnU‑Net spacing** using SimpleITK (linear for images, nearest for labels).\n",
    "- Normalize:\n",
    "  - **CT:** clip to \\[-125, 275\\] HU then scale to 0–1 (spleen‑friendly window).\n",
    "  - **MRI:** z‑score inside the foreground.\n",
    "- Random augmentations: flips, small rotations/scales, gamma (light).\n",
    "\n",
    "> You can expand this with MONAI/TorchIO later; we keep it minimal here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7e8e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import nibabel as nib\n",
    "import SimpleITK as sitk\n",
    "\n",
    "def load_nii(path):\n",
    "    img = sitk.ReadImage(path)\n",
    "    arr = sitk.GetArrayFromImage(img)  # z,y,x\n",
    "    spacing = img.GetSpacing()[::-1]   # to z,y,x\n",
    "    return arr.astype(np.float32), np.array(spacing, dtype=np.float32), img\n",
    "\n",
    "def sitk_resample_to_spacing(image_sitk, target_spacing, is_label=False):\n",
    "    orig_spacing = image_sitk.GetSpacing()\n",
    "    orig_size = image_sitk.GetSize()\n",
    "    target_spacing = tuple(target_spacing[::-1])  # sitk uses x,y,z\n",
    "    new_size = [int(round(osz*ospc/tspc)) for osz,ospc,tspc in zip(orig_size, orig_spacing, target_spacing)]\n",
    "    res = sitk.Resample(\n",
    "        image_sitk,\n",
    "        new_size,\n",
    "        sitk.Transform(),\n",
    "        sitk.sitkNearestNeighbor if is_label else sitk.sitkBSpline,\n",
    "        image_sitk.GetOrigin(),\n",
    "        target_spacing,\n",
    "        image_sitk.GetDirection(),\n",
    "        0,\n",
    "        image_sitk.GetPixelID()\n",
    "    )\n",
    "    return res\n",
    "\n",
    "def normalize_ct_hu(x):\n",
    "    # Window for abdominal organs ~[-125, 275], then scale to [0,1]\n",
    "    x = np.clip(x, -125, 275)\n",
    "    x = (x + 125) / (275 + 125)\n",
    "    return x.astype(np.float32)\n",
    "\n",
    "def normalize_mri_zscore(x, mask=None, eps=1e-6):\n",
    "    if mask is None:\n",
    "        mask = x != 0\n",
    "    m = x[mask].mean() if mask.any() else x.mean()\n",
    "    s = x[mask].std() if mask.any() else x.std()\n",
    "    return ((x - m) / (s + eps)).astype(np.float32)\n",
    "\n",
    "def random_augment(vol, seg):\n",
    "    # minimal 3D augmentations: random flips & gamma\n",
    "    if random.random() < 0.5:\n",
    "        vol = vol[::-1].copy(); seg = seg[::-1].copy()\n",
    "    if random.random() < 0.5:\n",
    "        vol = vol[:, ::-1].copy(); seg = seg[:, ::-1].copy()\n",
    "    if random.random() < 0.5:\n",
    "        vol = vol[:, :, ::-1].copy(); seg = seg[:, :, ::-1].copy()\n",
    "    # random gamma\n",
    "    if random.random() < 0.3:\n",
    "        g = 0.7 + 0.6*random.random()\n",
    "        vmin, vmax = vol.min(), vol.max()\n",
    "        vol = ((vol - vmin) / (vmax - vmin + 1e-6)) ** g\n",
    "        vol = vol * (vmax - vmin) + vmin\n",
    "    return vol, seg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714456df",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class NiftiPairDataset(Dataset):\n",
    "    def __init__(self, list_file, patch, spacing_target, modality=\"CT\", training=True):\n",
    "        self.items = [l.strip().split(\",\") for l in open(list_file) if l.strip()]\n",
    "        self.patch = patch\n",
    "        self.spacing_target = np.array(spacing_target, dtype=np.float32)\n",
    "        self.modality = modality\n",
    "        self.training = training\n",
    "\n",
    "    def _crop_or_pad(self, v, s):\n",
    "        # center crop or pad to patch size\n",
    "        Pz, Py, Px = self.patch\n",
    "        z, y, x = v.shape\n",
    "        outv = np.zeros(self.patch, np.float32)\n",
    "        outs = np.zeros(self.patch, np.int16)\n",
    "        sz = max(0, (Pz - z)//2); ez = sz + z\n",
    "        sy = max(0, (Py - y)//2); ey = sy + y\n",
    "        sx = max(0, (Px - x)//2); ex = sx + x\n",
    "\n",
    "        cz = max(0, (z - Pz)//2); cz2 = cz + min(Pz, z)\n",
    "        cy = max(0, (y - Py)//2); cy2 = cy + min(Py, y)\n",
    "        cx = max(0, (x - Px)//2); cx2 = cx + min(Px, x)\n",
    "\n",
    "        outv[sz:ez, sy:ey, sx:ex] = v[cz:cz2, cy:cy2, cx:cx2]\n",
    "        outs[sz:ez, sy:ey, sx:ex] = s[cz:cz2, cy:cy2, cx:cx2]\n",
    "        return outv, outs\n",
    "\n",
    "    def __len__(self): return len(self.items)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        ipath, lpath = self.items[idx]\n",
    "        img_sitk = sitk.ReadImage(ipath); lab_sitk = sitk.ReadImage(lpath)\n",
    "        img_rs = sitk_resample_to_spacing(img_sitk, self.spacing_target, is_label=False)\n",
    "        lab_rs = sitk_resample_to_spacing(lab_sitk, self.spacing_target, is_label=True)\n",
    "        vol = sitk.GetArrayFromImage(img_rs).astype(np.float32)  # z,y,x\n",
    "        seg = sitk.GetArrayFromImage(lab_rs).astype(np.int16)\n",
    "\n",
    "        if self.modality == \"CT\":\n",
    "            vol = normalize_ct_hu(vol)\n",
    "        else:\n",
    "            # MRI: foreground mask where not 0\n",
    "            vol = normalize_mri_zscore(vol, vol != 0)\n",
    "\n",
    "        if self.training:\n",
    "            vol, seg = random_augment(vol, seg)\n",
    "\n",
    "        vol, seg = self._crop_or_pad(vol, seg)\n",
    "\n",
    "        vol = vol[None, ...]               # (1, z, y, x)\n",
    "        onehot = np.zeros((NUM_CLASSES,)+seg.shape, np.float32)\n",
    "        for c in range(NUM_CLASSES):\n",
    "            onehot[c] = (seg == c)\n",
    "        return torch.from_numpy(vol), torch.from_numpy(onehot), torch.from_numpy(seg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cccba597",
   "metadata": {},
   "source": [
    "## Model: Residual U‑Net 3D with deep supervision\n",
    "- Residual conv blocks (3D) with InstanceNorm.\n",
    "- 4 encoder stages + 4 decoder stages.\n",
    "- **Deep supervision**: auxiliary logits at 3 decoder stages (down‑weighted in the loss).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d57e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ConvBlock3d(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv3d(in_ch, out_ch, 3, padding=1, bias=False)\n",
    "        self.in1   = nn.InstanceNorm3d(out_ch, affine=True)\n",
    "        self.conv2 = nn.Conv3d(out_ch, out_ch, 3, padding=1, bias=False)\n",
    "        self.in2   = nn.InstanceNorm3d(out_ch, affine=True)\n",
    "        self.act   = nn.LeakyReLU(0.01, inplace=True)\n",
    "        self.skip  = nn.Conv3d(in_ch, out_ch, 1, bias=False) if in_ch != out_ch else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        s = self.skip(x)\n",
    "        x = self.conv1(x); x = self.in1(x); x = self.act(x)\n",
    "        x = self.conv2(x); x = self.in2(x)\n",
    "        return self.act(x + s)\n",
    "\n",
    "class UpBlock3d(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.up = nn.ConvTranspose3d(in_ch, out_ch, kernel_size=2, stride=2)\n",
    "        self.conv = ConvBlock3d(in_ch, out_ch)  # after concat\n",
    "\n",
    "    def forward(self, x, skip):\n",
    "        x = self.up(x)\n",
    "        # pad/crop to match if needed\n",
    "        dz, dy, dx = skip.shape[2]-x.shape[2], skip.shape[3]-x.shape[3], skip.shape[4]-x.shape[4]\n",
    "        x = F.pad(x, (0, max(0,dx), 0, max(0,dy), 0, max(0,dz)))\n",
    "        if dz<0 or dy<0 or dx<0:\n",
    "            x = x[:, :, :skip.shape[2], :skip.shape[3], :skip.shape[4]]\n",
    "        x = torch.cat([x, skip], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "class ResidualUNet3D_DS(nn.Module):\n",
    "    def __init__(self, in_ch=1, n_classes=2, base=32):\n",
    "        super().__init__()\n",
    "        chs = [base, base*2, base*4, base*8, base*16]\n",
    "\n",
    "        # encoder\n",
    "        self.e1 = ConvBlock3d(in_ch, chs[0])\n",
    "        self.e2 = ConvBlock3d(chs[0], chs[1])\n",
    "        self.e3 = ConvBlock3d(chs[1], chs[2])\n",
    "        self.e4 = ConvBlock3d(chs[2], chs[3])\n",
    "        self.bottleneck = ConvBlock3d(chs[3], chs[4])\n",
    "\n",
    "        self.pool = nn.MaxPool3d(2)\n",
    "\n",
    "        # decoder\n",
    "        self.u4 = UpBlock3d(chs[4], chs[3])\n",
    "        self.u3 = UpBlock3d(chs[3], chs[2])\n",
    "        self.u2 = UpBlock3d(chs[2], chs[1])\n",
    "        self.u1 = UpBlock3d(chs[1], chs[0])\n",
    "\n",
    "        # logits (deep supervision at three decoder scales)\n",
    "        self.out_main = nn.Conv3d(chs[0], n_classes, 1)\n",
    "        self.out_ds2  = nn.Conv3d(chs[1], n_classes, 1)\n",
    "        self.out_ds3  = nn.Conv3d(chs[2], n_classes, 1)\n",
    "        self.out_ds4  = nn.Conv3d(chs[3], n_classes, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        e1 = self.e1(x)\n",
    "        e2 = self.e2(self.pool(e1))\n",
    "        e3 = self.e3(self.pool(e2))\n",
    "        e4 = self.e4(self.pool(e3))\n",
    "        bn = self.bottleneck(self.pool(e4))\n",
    "\n",
    "        d4 = self.u4(bn, e4)\n",
    "        d3 = self.u3(d4, e3)\n",
    "        d2 = self.u2(d3, e2)\n",
    "        d1 = self.u1(d2, e1)\n",
    "\n",
    "        out_main = self.out_main(d1)\n",
    "        # upsample ds outputs to main resolution\n",
    "        ds2 = F.interpolate(self.out_ds2(d2), size=out_main.shape[2:], mode=\"trilinear\", align_corners=False)\n",
    "        ds3 = F.interpolate(self.out_ds3(d3), size=out_main.shape[2:], mode=\"trilinear\", align_corners=False)\n",
    "        ds4 = F.interpolate(self.out_ds4(d4), size=out_main.shape[2:], mode=\"trilinear\", align_corners=False)\n",
    "        return out_main, ds2, ds3, ds4\n",
    "\n",
    "# quick shape/param check\n",
    "m = ResidualUNet3D_DS(in_ch=IN_CHANNELS, n_classes=NUM_CLASSES, base=32).to(device)\n",
    "x = torch.randn(1, IN_CHANNELS, *PATCH).to(device)\n",
    "with torch.no_grad():\n",
    "    outs = m(x)\n",
    "print(\"Output shapes:\", [o.shape for o in outs])\n",
    "print(\"Params (M):\", sum(p.numel() for p in m.parameters())/1e6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b840fc5d",
   "metadata": {},
   "source": [
    "## Losses & metrics\n",
    "- **Soft Dice + Cross‑Entropy** combined.\n",
    "- Deep supervision with weights `[1.0, 0.5, 0.25, 0.125]`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e41991",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def soft_dice_loss(logits, targets, eps=1e-6):\n",
    "    # logits: (B,C,Z,Y,X), targets: one-hot (B,C,Z,Y,X)\n",
    "    probs = torch.softmax(logits, dim=1)\n",
    "    dims = (0,2,3,4)\n",
    "    intersect = torch.sum(probs * targets, dims)\n",
    "    denom = torch.sum(probs, dims) + torch.sum(targets, dims)\n",
    "    dice = (2*intersect + eps) / (denom + eps)\n",
    "    return 1 - dice.mean()\n",
    "\n",
    "ce = nn.CrossEntropyLoss()\n",
    "\n",
    "def combined_loss(logits_list, targets_onehot, targets_label):\n",
    "    weights = [1.0, 0.5, 0.25, 0.125]\n",
    "    tot = 0.0\n",
    "    for w,logits in zip(weights, logits_list):\n",
    "        tot += w*(soft_dice_loss(logits, targets_onehot) + ce(logits, targets_label.long()))\n",
    "    return tot / sum(weights)\n",
    "\n",
    "def dice_score_from_logits(logits, targets_label, c=1, eps=1e-6):\n",
    "    # computes single-class Dice (e.g., organ)\n",
    "    pred = torch.argmax(logits, dim=1)\n",
    "    inter = torch.sum((pred==c) & (targets_label==c)).float()\n",
    "    denom = torch.sum(pred==c).float() + torch.sum(targets_label==c).float()\n",
    "    return (2*inter + eps)/(denom + eps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5e6339",
   "metadata": {},
   "source": [
    "## DataLoaders\n",
    "Reads the nnU‑Net fold‑0 splits we created earlier. If you haven’t created them yet, run the helper in the other notebook to export `splits_final.json` into list files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea5a68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# build loaders\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "train_ds = NiftiPairDataset(LIST_TRAIN, PATCH, np.array(spacing), modality=MODALITY, training=True)\n",
    "val_ds   = NiftiPairDataset(LIST_VAL,   PATCH, np.array(spacing), modality=MODALITY, training=False)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,  num_workers=NUM_WORKERS, pin_memory=True)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=1,          shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "\n",
    "len(train_ds), len(val_ds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3879c8e",
   "metadata": {},
   "source": [
    "## Training loop (AMP, checkpoint by best val Dice)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b326e437",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_one_epoch(model, loader, opt, scaler):\n",
    "    model.train()\n",
    "    total = 0.0\n",
    "    for vol, onehot, lab in loader:\n",
    "        vol = vol.to(device, non_blocking=True)\n",
    "        onehot = onehot.to(device, non_blocking=True)\n",
    "        lab = lab.to(device, non_blocking=True)\n",
    "\n",
    "        opt.zero_grad(set_to_none=True)\n",
    "        with torch.cuda.amp.autocast(enabled=AMP):\n",
    "            outs = model(vol)\n",
    "            loss = combined_loss(outs, onehot, lab)\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(opt)\n",
    "        scaler.update()\n",
    "        total += loss.item()\n",
    "    return total/len(loader)\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate(model, loader):\n",
    "    model.eval()\n",
    "    dices = []\n",
    "    for vol, onehot, lab in loader:\n",
    "        vol = vol.to(device, non_blocking=True)\n",
    "        lab = lab.to(device, non_blocking=True)\n",
    "        logits = model(vol)[0]\n",
    "        d = dice_score_from_logits(logits, lab, c=1).item()\n",
    "        dices.append(d)\n",
    "    return float(np.mean(dices)) if dices else 0.0\n",
    "\n",
    "def save_ckpt(state, path):\n",
    "    torch.save(state, path)\n",
    "\n",
    "model = ResidualUNet3D_DS(in_ch=IN_CHANNELS, n_classes=NUM_CLASSES, base=32).to(device)\n",
    "opt = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=AMP)\n",
    "\n",
    "best = -1\n",
    "log_csv = os.path.join(OUT_DIR, \"log.csv\")\n",
    "with open(log_csv, \"w\", newline=\"\") as f:\n",
    "    w=csv.writer(f); w.writerow([\"epoch\",\"train_loss\",\"val_dice\"])\n",
    "\n",
    "for epoch in range(1, MAX_EPOCHS+1):\n",
    "    t0=time.time()\n",
    "    tl = train_one_epoch(model, train_loader, opt, scaler)\n",
    "    vd = validate(model, val_loader)\n",
    "    with open(log_csv, \"a\", newline=\"\") as f:\n",
    "        csv.writer(f).writerow([epoch, tl, vd])\n",
    "    if vd > best:\n",
    "        best = vd\n",
    "        save_ckpt({\"epoch\":epoch, \"state_dict\":model.state_dict(), \"val_dice\":vd},\n",
    "                  os.path.join(OUT_DIR, \"unet3d_best.pth\"))\n",
    "    print(f\"Epoch {epoch:03d} | loss {tl:.4f} | val Dice {vd:.4f} | best {best:.4f} | {time.time()-t0:.1f}s\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0d2f56",
   "metadata": {},
   "source": [
    "## Sliding‑window prediction (with optional mirror TTA)\n",
    "Outputs a NIfTI file aligned to the input image geometry.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257b8df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sliding_window_predict(vol_np, model, patch, overlap=0.5, tta_mirror=False):\n",
    "    model.eval()\n",
    "    sz, sy, sx = vol_np.shape\n",
    "    pz, py, px = patch\n",
    "    stz = max(1, int(pz*(1-overlap)))\n",
    "    sty = max(1, int(py*(1-overlap)))\n",
    "    stx = max(1, int(px*(1-overlap)))\n",
    "\n",
    "    prob = np.zeros((NUM_CLASSES, sz, sy, sx), np.float32)\n",
    "    weight = np.zeros((sz, sy, sx), np.float32)\n",
    "\n",
    "    def run_patch(inp):\n",
    "        ten = torch.from_numpy(inp[None, None]).to(device)\n",
    "        with torch.no_grad(), torch.cuda.amp.autocast(enabled=AMP):\n",
    "            logits = model(ten)[0]\n",
    "            p = torch.softmax(logits, dim=1)[0].cpu().numpy()\n",
    "        return p\n",
    "\n",
    "    def put_prob(p, z0,y0,x0):\n",
    "        prob[:, z0:z0+p.shape[1], y0:y0+p.shape[2], x0:x0+p.shape[3]] += p\n",
    "        weight[z0:z0+p.shape[1], y0:y0+p.shape[2], x0:x0+p.shape[3]] += 1\n",
    "\n",
    "    for z in range(0, max(1, sz - pz + 1), stz):\n",
    "        for y in range(0, max(1, sy - py + 1), sty):\n",
    "            for x in range(0, max(1, sx - px + 1), stx):\n",
    "                patch_np = vol_np[z:z+pz, y:y+py, x:x+px]\n",
    "                # pad if needed\n",
    "                pad = [(0, max(0, pz - patch_np.shape[0])),\n",
    "                       (0, max(0, py - patch_np.shape[1])),\n",
    "                       (0, max(0, px - patch_np.shape[2]))]\n",
    "                patch_np = np.pad(patch_np, pad, mode=\"edge\")\n",
    "                p = run_patch(patch_np)\n",
    "                if tta_mirror:\n",
    "                    p = (p\n",
    "                         + np.flip(run_patch(np.flip(patch_np, 0)), 1)\n",
    "                         + np.flip(run_patch(np.flip(patch_np, 1)), 2)\n",
    "                         + np.flip(run_patch(np.flip(patch_np, 2)), 3)) / 4.0\n",
    "                put_prob(p[:, :min(pz, sz - z),\n",
    "                            :min(py, sy - y),\n",
    "                            :min(px, sx - x)], z, y, x)\n",
    "    prob /= np.maximum(weight[None], 1e-6)\n",
    "    seg = np.argmax(prob, axis=0).astype(np.uint8)\n",
    "    return seg, prob\n",
    "\n",
    "def predict_single(image_path, out_path):\n",
    "    # read original image and resample to spacing\n",
    "    img_sitk = sitk.ReadImage(image_path)\n",
    "    img_rs = sitk_resample_to_spacing(img_sitk, np.array(spacing), is_label=False)\n",
    "    vol = sitk.GetArrayFromImage(img_rs).astype(np.float32)\n",
    "    vol = normalize_mri_zscore(vol) if MODALITY==\"MRI\" else normalize_ct_hu(vol)\n",
    "    seg, prob = sliding_window_predict(vol, model, PATCH, overlap=0.5, tta_mirror=TTA_MIRROR)\n",
    "    # bring seg back to original spacing/size\n",
    "    seg_sitk = sitk.GetImageFromArray(seg.astype(np.uint8))\n",
    "    seg_sitk.CopyInformation(img_rs)\n",
    "    seg_back = sitk.Resample(seg_sitk, img_sitk, sitk.Transform(),\n",
    "                             sitk.sitkNearestNeighbor, 0, sitk.sitkUInt8)\n",
    "    sitk.WriteImage(seg_back, out_path)\n",
    "    print(\"Saved:\", out_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff6f129",
   "metadata": {},
   "source": [
    "## Example prediction on one test case (edit the filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b353784",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example (Heart): change la_001 to a real file present in your imagesTs\n",
    "test_img = f\"{DATA_ROOT}/MSD/{TASK}/imagesTs/la_001.nii.gz\"\n",
    "out_pred = os.path.join(OUT_DIR, \"la_001_pred.nii.gz\")\n",
    "if os.path.exists(test_img):\n",
    "    predict_single(test_img, out_pred)\n",
    "else:\n",
    "    print(\"Edit 'test_img' with a real imagesTs filename.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5221ff06",
   "metadata": {},
   "source": [
    "---\n",
    "### What next (roadmap inside this notebook)\n",
    "1) If VRAM allows, set `PATCH = nn_patch` printed earlier.\n",
    "2) Try **base=48** in the model for more capacity.\n",
    "3) Add **largest-component post‑processing** for Spleen/Heart.\n",
    "4) Enable **mirror TTA** at inference (`TTA_MIRROR=True`).\n",
    "5) Swap loss to **Dice + Focal** for heavy imbalance tasks.\n",
    "6) (Stretch) Replace backbone with a **UNETR‑lite** and add a **3D MAE** pretrainer.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c2d8044",
   "metadata": {},
   "source": [
    "# Self‑Contained 3D Segmentation — **v2** (SE‑Residual U‑Net++, TTA, LCC post‑proc, 3D‑MAE pretrainer)\n",
    "This notebook is **self-contained** and includes:\n",
    "\n",
    "- Reading **nnU‑Net v2** plans (to mirror spacing & patch size for fair comparison)\n",
    "\n",
    "- **CT/MRI normalization**, **resampling to target spacing** (SimpleITK), light aug\n",
    "\n",
    "- **SE‑Residual U‑Net++** (residual blocks + squeeze‑excitation + deep supervision)\n",
    "\n",
    "- **Training loop** (Dice+CE), **AMP**, optional **EMA**, checkpoint by best val Dice\n",
    "\n",
    "- **Sliding‑window prediction** with **mirror TTA** + **Gaussian blending**\n",
    "\n",
    "- **Largest-Component Post‑Processing** (good for single-organ tasks)\n",
    "\n",
    "- **Minimal 3D Masked Autoencoder (MAE) pretrainer** + **transfer** to segmentation encoder\n",
    "\n",
    "\n",
    "> Place this notebook anywhere (e.g., repo root). Set paths in the config cell.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "643b8ca8-bbc9-4c58-b7ea-411adc692c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote lists/Task02_Heart_train_fold0.txt  (16 pairs)\n",
      "Wrote lists/Task02_Heart_val_fold0.txt  (4 pairs)\n",
      "Wrote lists/Task09_Spleen_train_fold0.txt  (32 pairs)\n",
      "Wrote lists/Task09_Spleen_val_fold0.txt  (9 pairs)\n"
     ]
    }
   ],
   "source": [
    "# === Build ./lists/* from nnU-Net fold-0 splits (Heart + Spleen) ===\n",
    "import os, json, pathlib\n",
    "\n",
    "def _find_case(root, cid):\n",
    "    for ext in (\".nii.gz\", \".nii\"):\n",
    "        p = os.path.join(root, f\"{cid}{ext}\")\n",
    "        if os.path.exists(p):\n",
    "            return p\n",
    "    raise FileNotFoundError(f\"Case not found with .nii[.gz]: {root}/{cid}\")\n",
    "\n",
    "def make_lists(ds_id: int, name: str, task: str):\n",
    "    split_p = f\"/home/htetaung/data/nnunet_preprocessed/Dataset0{ds_id:02d}_{name}/splits_final.json\"\n",
    "    sp = json.load(open(split_p))[0]   # fold-0\n",
    "    imgs = f\"/home/htetaung/data/MSD/{task}/imagesTr\"\n",
    "    labs = f\"/home/htetaung/data/MSD/{task}/labelsTr\"\n",
    "    outdir = pathlib.Path(\"./lists\"); outdir.mkdir(exist_ok=True)\n",
    "\n",
    "    for tag, ids in ((\"train_fold0\", sp[\"train\"]), (\"val_fold0\", sp[\"val\"])):\n",
    "        out = outdir / f\"{task}_{tag}.txt\"\n",
    "        with open(out, \"w\") as f:\n",
    "            for cid in ids:\n",
    "                ip = _find_case(imgs, cid)\n",
    "                lp = _find_case(labs, cid)\n",
    "                f.write(f\"{ip},{lp}\\n\")\n",
    "        print(f\"Wrote {out}  ({len(ids)} pairs)\")\n",
    "\n",
    "# Heart (Dataset002) + Spleen (Dataset009)\n",
    "make_lists(2, \"Heart\",  \"Task02_Heart\")\n",
    "make_lists(9, \"Spleen\", \"Task09_Spleen\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ab0634b-4e75-4f40-8d17-e37a821520fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK: ./lists/Task02_Heart_train_fold0.txt and ./lists/Task02_Heart_val_fold0.txt\n"
     ]
    }
   ],
   "source": [
    "import os, sys, json\n",
    "LIST_TRAIN = \"./lists/Task02_Heart_train_fold0.txt\"\n",
    "LIST_VAL   = \"./lists/Task02_Heart_val_fold0.txt\"\n",
    "for p in (LIST_TRAIN, LIST_VAL):\n",
    "    assert os.path.exists(p), f\"Missing: {p}\"\n",
    "print(\"OK:\", LIST_TRAIN, \"and\", LIST_VAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8447ac8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==== Config ====\n",
    "DATA_ROOT = \"/home/htetaung/data\"            # MSD + nnU-Net folders live here\n",
    "TASK      = \"Task02_Heart\"                   # or \"Task09_Spleen\"\n",
    "DS_ID     = 2 if TASK == \"Task02_Heart\" else 9\n",
    "NAME      = \"Heart\" if DS_ID == 2 else \"Spleen\"\n",
    "FOLD      = 0\n",
    "MODALITY  = \"MRI\" if TASK == \"Task02_Heart\" else \"CT\"\n",
    "IN_CHANNELS = 1\n",
    "NUM_CLASSES = 2                              # bg + organ (Heart/Spleen)\n",
    "PATCH      = (80, 192, 160)                    # you may set to nnU-Net patch printed below if VRAM allows\n",
    "BATCH_SIZE = 2\n",
    "MAX_EPOCHS = 50\n",
    "NUM_WORKERS = 4\n",
    "AMP = True\n",
    "USE_EMA = True                               # Exponential Moving Average for stability\n",
    "OVERLAP = 0.5                                # sliding window overlap\n",
    "TTA_MIRROR = True                            # mirror test-time augmentation\n",
    "POSTPROC_KEEP_LARGEST = True                 # largest-component post-proc for class 1\n",
    "\n",
    "OUT_DIR = f\"./runs_selfcontained_v2/{TASK}_seresunetpp_fold{FOLD}\"\n",
    "LIST_TRAIN = f\"./lists/{TASK}_train_fold{FOLD}.txt\"   # reuse nnU-Net fold split\n",
    "LIST_VAL   = f\"./lists/{TASK}_val_fold{FOLD}.txt\"\n",
    "\n",
    "# MAE pretraining knobs\n",
    "MAE_PATCH  = (64, 64, 64)\n",
    "MAE_MASK_RATIO = 0.8\n",
    "MAE_EPOCHS = 10\n",
    "MAE_OUT    = f\"./runs_selfcontained_v2/{TASK}_mae_pretrain\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ae86824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch: 2.5.1\n",
      "CUDA: True\n",
      "GPU: NVIDIA GeForce RTX 4070\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ==== Imports & device ====\n",
    "import os, json, time, math, random, csv, glob\n",
    "from pathlib import Path\n",
    "from typing import Tuple\n",
    "import numpy as np\n",
    "import torch, torch.nn as nn, torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "print(\"Torch:\", torch.__version__)\n",
    "print(\"CUDA:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1791a1b",
   "metadata": {},
   "source": [
    "## Read nnU‑Net plans (spacing & patch size)\n",
    "Use these to align geometry with the supervised anchor. You may set `PATCH` to `nn_patch` if VRAM allows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70118acd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 2 Heart -> spacing=[1.3700000047683716, 1.25, 1.25], patch_size=(80, 192, 160), batch_size=2\n",
      "Notebook PATCH = (80, 192, 160) (set to nn_patch if VRAM allows)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def read_nnunet_cfg(ds_id, name, data_root=DATA_ROOT):\n",
    "    base = f\"{data_root}/nnunet_preprocessed/Dataset0{ds_id:02d}_{name}\"\n",
    "    with open(f\"{base}/nnUNetPlans.json\") as f:\n",
    "        plans = json.load(f)\n",
    "    cfg = plans.get(\"configurations\", {}).get(\"3d_fullres\", {})\n",
    "    spacing = (cfg.get(\"spacing\") or cfg.get(\"resampling_target_spacing\") or\n",
    "               plans.get(\"target_spacing\") or plans.get(\"spacing\"))\n",
    "    patch_size = tuple(cfg.get(\"patch_size\") or ())\n",
    "    batch_size = cfg.get(\"batch_size\")\n",
    "    return spacing, patch_size, batch_size\n",
    "\n",
    "spacing, nn_patch, nn_bs = read_nnunet_cfg(DS_ID, NAME)\n",
    "print(f\"Dataset {DS_ID} {NAME} -> spacing={spacing}, patch_size={nn_patch}, batch_size={nn_bs}\")\n",
    "print(\"Notebook PATCH =\", PATCH, \"(set to nn_patch if VRAM allows)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a572ae66",
   "metadata": {},
   "source": [
    "## I/O, resampling, normalization & augmentation\n",
    "- Resample to nnU‑Net spacing via **SimpleITK** (BSpline for image, Nearest for label)\n",
    "- **CT**: clip to [-125, 275] HU → scale to [0,1].  **MRI**: z‑score in foreground\n",
    "- Light 3D aug: flips + gamma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69b32a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import SimpleITK as sitk\n",
    "\n",
    "def sitk_resample_to_spacing(image_sitk, target_spacing_xyz, is_label=False):\n",
    "    # target_spacing_xyz expects (z, y, x)\n",
    "    orig_spacing = image_sitk.GetSpacing()     # (x,y,z)\n",
    "    target = (float(target_spacing_xyz[2]), float(target_spacing_xyz[1]), float(target_spacing_xyz[0]))\n",
    "    orig_size = image_sitk.GetSize()           # (x,y,z)\n",
    "    new_size = [int(round(osz*ospc/tspc)) for osz,ospc,tspc in zip(orig_size, orig_spacing, target)]\n",
    "    res = sitk.Resample(\n",
    "        image_sitk, new_size, sitk.Transform(),\n",
    "        sitk.sitkNearestNeighbor if is_label else sitk.sitkBSpline,\n",
    "        image_sitk.GetOrigin(), target, image_sitk.GetDirection(),\n",
    "        0, image_sitk.GetPixelID()\n",
    "    )\n",
    "    return res\n",
    "\n",
    "def normalize_ct_hu(x):\n",
    "    x = np.clip(x, -125, 275)\n",
    "    x = (x + 125)/400.0\n",
    "    return x.astype(np.float32)\n",
    "\n",
    "def normalize_mri_z(x, mask=None, eps=1e-6):\n",
    "    if mask is None: mask = x != 0\n",
    "    m = x[mask].mean() if mask.any() else x.mean()\n",
    "    s = x[mask].std() if mask.any() else x.std()\n",
    "    return ((x - m)/(s+eps)).astype(np.float32)\n",
    "\n",
    "def random_aug(vol, seg):\n",
    "    if random.random() < 0.5: vol = vol[::-1].copy(); seg = seg[::-1].copy()\n",
    "    if random.random() < 0.5: vol = vol[:, ::-1].copy(); seg = seg[:, ::-1].copy()\n",
    "    if random.random() < 0.5: vol = vol[:, :, ::-1].copy(); seg = seg[:, :, ::-1].copy()\n",
    "    if random.random() < 0.3:\n",
    "        g = 0.7 + 0.6*random.random()\n",
    "        vmin, vmax = vol.min(), vol.max()\n",
    "        vol = ((vol - vmin)/(vmax - vmin + 1e-6))**g\n",
    "        vol = vol*(vmax - vmin) + vmin\n",
    "    return vol, seg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d8e6891",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class PairListDataset(Dataset):\n",
    "    def __init__(self, list_file, patch, spacing, modality=\"CT\", training=True, fg_ratio=0.5):\n",
    "        self.items = [l.strip().split(\",\") for l in open(list_file) if l.strip()]\n",
    "        self.patch = patch\n",
    "        self.spacing = np.array(spacing, dtype=np.float32)\n",
    "        self.modality = modality\n",
    "        self.training = training\n",
    "        self.fg_ratio = fg_ratio if training else 0.0\n",
    "\n",
    "    def _rand_center(self, seg):\n",
    "        z, y, x = np.where(seg > 0)\n",
    "        if len(z)==0:\n",
    "            return [np.random.randint(0, seg.shape[0]),\n",
    "                    np.random.randint(0, seg.shape[1]),\n",
    "                    np.random.randint(0, seg.shape[2])]\n",
    "        i = np.random.randint(0, len(z))\n",
    "        return [int(z[i]), int(y[i]), int(x[i])]\n",
    "\n",
    "    def _extract_patch(self, v, s, center=None):\n",
    "        Pz, Py, Px = self.patch\n",
    "        Z, Y, X = v.shape\n",
    "        if center is None:\n",
    "            cz = np.random.randint(0, max(1, Z - Pz + 1))\n",
    "            cy = np.random.randint(0, max(1, Y - Py + 1))\n",
    "            cx = np.random.randint(0, max(1, X - Px + 1))\n",
    "        else:\n",
    "            cz = max(0, min(center[0] - Pz//2, Z - Pz))\n",
    "            cy = max(0, min(center[1] - Py//2, Y - Py))\n",
    "            cx = max(0, min(center[2] - Px//2, X - Px))\n",
    "        patch_v = v[cz:cz+Pz, cy:cy+Py, cx:cx+Px]\n",
    "        patch_s = s[cz:cz+Pz, cy:cy+Py, cx:cx+Px]\n",
    "        # pad if at border\n",
    "        padz = Pz - patch_v.shape[0]; pady = Py - patch_v.shape[1]; padx = Px - patch_v.shape[2]\n",
    "        if padz>0 or pady>0 or padx>0:\n",
    "            pad = [(0,padz),(0,pady),(0,padx)]\n",
    "            patch_v = np.pad(patch_v, pad, mode=\"edge\")\n",
    "            patch_s = np.pad(patch_s, pad, mode=\"edge\")\n",
    "        return patch_v, patch_s\n",
    "\n",
    "    def __len__(self): return len(self.items)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        ip, lp = self.items[idx]\n",
    "        i_sitk = sitk.ReadImage(ip); l_sitk = sitk.ReadImage(lp)\n",
    "        i_rs = sitk_resample_to_spacing(i_sitk, self.spacing, is_label=False)\n",
    "        l_rs = sitk_resample_to_spacing(l_sitk, self.spacing, is_label=True)\n",
    "        vol = sitk.GetArrayFromImage(i_rs).astype(np.float32)\n",
    "        seg = sitk.GetArrayFromImage(l_rs).astype(np.int16)\n",
    "\n",
    "        vol = normalize_ct_hu(vol) if self.modality==\"CT\" else normalize_mri_z(vol, vol!=0)\n",
    "        if self.training:\n",
    "            vol, seg = random_aug(vol, seg)\n",
    "            if random.random() < self.fg_ratio:\n",
    "                center = self._rand_center(seg)\n",
    "                vol, seg = self._extract_patch(vol, seg, center=center)\n",
    "            else:\n",
    "                vol, seg = self._extract_patch(vol, seg, center=None)\n",
    "        else:\n",
    "            vol, seg = self._extract_patch(vol, seg, center=None)\n",
    "\n",
    "        vol = vol[None, ...]\n",
    "        onehot = np.zeros((NUM_CLASSES,)+seg.shape, np.float32)\n",
    "        for c in range(NUM_CLASSES):\n",
    "            onehot[c] = (seg==c)\n",
    "        return torch.from_numpy(vol), torch.from_numpy(onehot), torch.from_numpy(seg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3abcad",
   "metadata": {},
   "source": [
    "## SE‑Residual U‑Net++ (deep supervision)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3644f78c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shapes: [torch.Size([1, 2, 80, 192, 160]), torch.Size([1, 2, 80, 192, 160]), torch.Size([1, 2, 80, 192, 160]), torch.Size([1, 2, 80, 192, 160])]\n",
      "Params (M): 23.038112\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class SEBlock(nn.Module):\n",
    "    def __init__(self, ch, r=8):\n",
    "        super().__init__()\n",
    "        self.pool = nn.AdaptiveAvgPool3d(1)\n",
    "        self.fc1 = nn.Conv3d(ch, ch//r, 1)\n",
    "        self.fc2 = nn.Conv3d(ch//r, ch, 1)\n",
    "        self.act = nn.ReLU(inplace=True)\n",
    "        self.gate = nn.Sigmoid()\n",
    "    def forward(self, x):\n",
    "        s = self.pool(x)\n",
    "        s = self.fc2(self.act(self.fc1(s)))\n",
    "        return x * self.gate(s)\n",
    "\n",
    "class ResSEBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv3d(in_ch, out_ch, 3, padding=1, bias=False)\n",
    "        self.in1   = nn.InstanceNorm3d(out_ch, affine=True)\n",
    "        self.conv2 = nn.Conv3d(out_ch, out_ch, 3, padding=1, bias=False)\n",
    "        self.in2   = nn.InstanceNorm3d(out_ch, affine=True)\n",
    "        self.se    = SEBlock(out_ch)\n",
    "        self.act   = nn.LeakyReLU(0.01, inplace=True)\n",
    "        self.skip  = nn.Conv3d(in_ch, out_ch, 1, bias=False) if in_ch != out_ch else nn.Identity()\n",
    "    def forward(self, x):\n",
    "        s = self.skip(x)\n",
    "        x = self.act(self.in1(self.conv1(x)))\n",
    "        x = self.in2(self.conv2(x))\n",
    "        x = self.se(x)\n",
    "        return self.act(x + s)\n",
    "\n",
    "class UpBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.up = nn.ConvTranspose3d(in_ch, out_ch, 2, 2)\n",
    "        self.conv = ResSEBlock(in_ch, out_ch)\n",
    "    def forward(self, x, skip):\n",
    "        x = self.up(x)\n",
    "        dz, dy, dx = skip.shape[2]-x.shape[2], skip.shape[3]-x.shape[3], skip.shape[4]-x.shape[4]\n",
    "        x = F.pad(x, (0, max(0,dx), 0, max(0,dy), 0, max(0,dz)))\n",
    "        if dz<0 or dy<0 or dx<0:\n",
    "            x = x[:, :, :skip.shape[2], :skip.shape[3], :skip.shape[4]]\n",
    "        x = torch.cat([x, skip], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "class SEResUNetPP(nn.Module):\n",
    "    def __init__(self, in_ch=1, n_classes=2, base=32):\n",
    "        super().__init__()\n",
    "        chs = [base, base*2, base*4, base*8, base*16]\n",
    "        self.e1 = ResSEBlock(in_ch, chs[0])\n",
    "        self.e2 = ResSEBlock(chs[0], chs[1])\n",
    "        self.e3 = ResSEBlock(chs[1], chs[2])\n",
    "        self.e4 = ResSEBlock(chs[2], chs[3])\n",
    "        self.bottleneck = ResSEBlock(chs[3], chs[4])\n",
    "        self.pool = nn.MaxPool3d(2)\n",
    "        self.u4 = UpBlock(chs[4], chs[3])\n",
    "        self.u3 = UpBlock(chs[3], chs[2])\n",
    "        self.u2 = UpBlock(chs[2], chs[1])\n",
    "        self.u1 = UpBlock(chs[1], chs[0])\n",
    "        self.out_main = nn.Conv3d(chs[0], n_classes, 1)\n",
    "        self.out_ds2  = nn.Conv3d(chs[1], n_classes, 1)\n",
    "        self.out_ds3  = nn.Conv3d(chs[2], n_classes, 1)\n",
    "        self.out_ds4  = nn.Conv3d(chs[3], n_classes, 1)\n",
    "    def forward(self, x):\n",
    "        e1 = self.e1(x)\n",
    "        e2 = self.e2(self.pool(e1))\n",
    "        e3 = self.e3(self.pool(e2))\n",
    "        e4 = self.e4(self.pool(e3))\n",
    "        bn = self.bottleneck(self.pool(e4))\n",
    "        d4 = self.u4(bn, e4)\n",
    "        d3 = self.u3(d4, e3)\n",
    "        d2 = self.u2(d3, e2)\n",
    "        d1 = self.u1(d2, e1)\n",
    "        o_main = self.out_main(d1)\n",
    "        o2 = F.interpolate(self.out_ds2(d2), size=o_main.shape[2:], mode=\"trilinear\", align_corners=False)\n",
    "        o3 = F.interpolate(self.out_ds3(d3), size=o_main.shape[2:], mode=\"trilinear\", align_corners=False)\n",
    "        o4 = F.interpolate(self.out_ds4(d4), size=o_main.shape[2:], mode=\"trilinear\", align_corners=False)\n",
    "        return o_main, o2, o3, o4\n",
    "\n",
    "# quick check\n",
    "tmp = SEResUNetPP(IN_CHANNELS, NUM_CLASSES, base=32).to(device)\n",
    "x = torch.randn(1, IN_CHANNELS, *PATCH).to(device)\n",
    "with torch.no_grad():\n",
    "    outs = tmp(x)\n",
    "print(\"Output shapes:\", [t.shape for t in outs])\n",
    "print(\"Params (M):\", sum(p.numel() for p in tmp.parameters())/1e6)\n",
    "del tmp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a5520d",
   "metadata": {},
   "source": [
    "## Losses, metrics, EMA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "711fe205",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def soft_dice_loss(logits, onehot, eps=1e-6):\n",
    "    probs = torch.softmax(logits, dim=1)\n",
    "    dims = (0,2,3,4)\n",
    "    inter = torch.sum(probs*onehot, dims)\n",
    "    denom = torch.sum(probs, dims) + torch.sum(onehot, dims)\n",
    "    dice = (2*inter + eps)/(denom + eps)\n",
    "    return 1 - dice.mean()\n",
    "\n",
    "ce = nn.CrossEntropyLoss()\n",
    "\n",
    "def combined_loss(logits_list, onehot, y):\n",
    "    weights = [1.0, 0.5, 0.25, 0.125]\n",
    "    loss = 0.0\n",
    "    for w,lg in zip(weights, logits_list):\n",
    "        loss += w*(soft_dice_loss(lg, onehot) + ce(lg, y.long()))\n",
    "    return loss/sum(weights)\n",
    "\n",
    "def dice_from_logits(logits, y, cls=1, eps=1e-6):\n",
    "    pred = torch.argmax(logits, dim=1)\n",
    "    inter = torch.sum((pred==cls) & (y==cls)).float()\n",
    "    denom = torch.sum(pred==cls).float() + torch.sum(y==cls).float()\n",
    "    return (2*inter + eps)/(denom + eps)\n",
    "\n",
    "class EMA:\n",
    "    def __init__(self, model, decay=0.999):\n",
    "        self.decay = decay\n",
    "        self.shadow = {k: v.detach().clone() for k,v in model.state_dict().items()}\n",
    "    def update(self, model):\n",
    "        with torch.no_grad():\n",
    "            for k,v in model.state_dict().items():\n",
    "                self.shadow[k].mul_(self.decay).add_(v.detach(), alpha=1-self.decay)\n",
    "    def apply_to(self, model):\n",
    "        model.load_state_dict(self.shadow, strict=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5d9e90",
   "metadata": {},
   "source": [
    "## DataLoaders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56dcf256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train/val: 16 4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "train_ds = PairListDataset(LIST_TRAIN, PATCH, spacing, modality=MODALITY, training=True, fg_ratio=0.6)\n",
    "val_ds   = PairListDataset(LIST_VAL,   PATCH, spacing, modality=MODALITY, training=False)\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,  num_workers=NUM_WORKERS, pin_memory=True)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=1,          shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "print(\"train/val:\", len(train_ds), len(val_ds))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d1ef46",
   "metadata": {},
   "source": [
    "## Train (AMP, optional EMA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "27530b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_48784/3750950814.py:36: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=AMP)\n",
      "/tmp/ipykernel_48784/3750950814.py:9: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=AMP):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | loss 0.9945 | valDice 0.0580 | best 0.0580\n",
      "Epoch 002 | loss 0.5611 | valDice 0.0672 | best 0.0672\n",
      "Epoch 003 | loss 0.4353 | valDice 0.0613 | best 0.0672\n",
      "Epoch 004 | loss 0.4136 | valDice 0.0914 | best 0.0914\n",
      "Epoch 005 | loss 0.3699 | valDice 0.1043 | best 0.1043\n",
      "Epoch 006 | loss 0.3411 | valDice 0.1146 | best 0.1146\n",
      "Epoch 007 | loss 0.2595 | valDice 0.1381 | best 0.1381\n",
      "Epoch 008 | loss 0.2851 | valDice 0.1490 | best 0.1490\n",
      "Epoch 009 | loss 0.2626 | valDice 0.1589 | best 0.1589\n",
      "Epoch 010 | loss 0.2087 | valDice 0.1640 | best 0.1640\n",
      "Epoch 011 | loss 0.2159 | valDice 0.1045 | best 0.1640\n",
      "Epoch 012 | loss 0.2499 | valDice 0.1624 | best 0.1640\n",
      "Epoch 013 | loss 0.2186 | valDice 0.1649 | best 0.1649\n",
      "Epoch 014 | loss 0.2040 | valDice 0.1759 | best 0.1759\n",
      "Epoch 015 | loss 0.1866 | valDice 0.1875 | best 0.1875\n",
      "Epoch 016 | loss 0.1945 | valDice 0.1750 | best 0.1875\n",
      "Epoch 017 | loss 0.1648 | valDice 0.2002 | best 0.2002\n",
      "Epoch 018 | loss 0.2116 | valDice 0.2024 | best 0.2024\n",
      "Epoch 019 | loss 0.1749 | valDice 0.1938 | best 0.2024\n",
      "Epoch 020 | loss 0.1573 | valDice 0.1868 | best 0.2024\n",
      "Epoch 021 | loss 0.1637 | valDice 0.1966 | best 0.2024\n",
      "Epoch 022 | loss 0.1283 | valDice 0.2023 | best 0.2024\n",
      "Epoch 023 | loss 0.1350 | valDice 0.2231 | best 0.2231\n",
      "Epoch 024 | loss 0.1853 | valDice 0.1599 | best 0.2231\n",
      "Epoch 025 | loss 0.1432 | valDice 0.1979 | best 0.2231\n",
      "Epoch 026 | loss 0.1590 | valDice 0.1454 | best 0.2231\n",
      "Epoch 027 | loss 0.1254 | valDice 0.2102 | best 0.2231\n",
      "Epoch 028 | loss 0.1261 | valDice 0.2147 | best 0.2231\n",
      "Epoch 029 | loss 0.1409 | valDice 0.2409 | best 0.2409\n",
      "Epoch 030 | loss 0.1507 | valDice 0.2094 | best 0.2409\n",
      "Epoch 031 | loss 0.1222 | valDice 0.1926 | best 0.2409\n",
      "Epoch 032 | loss 0.1215 | valDice 0.2199 | best 0.2409\n",
      "Epoch 033 | loss 0.1086 | valDice 0.2172 | best 0.2409\n",
      "Epoch 034 | loss 0.1166 | valDice 0.2058 | best 0.2409\n",
      "Epoch 035 | loss 0.1116 | valDice 0.2092 | best 0.2409\n",
      "Epoch 036 | loss 0.1009 | valDice 0.1832 | best 0.2409\n",
      "Epoch 037 | loss 0.1093 | valDice 0.2087 | best 0.2409\n",
      "Epoch 038 | loss 0.0999 | valDice 0.2193 | best 0.2409\n",
      "Epoch 039 | loss 0.1025 | valDice 0.2171 | best 0.2409\n",
      "Epoch 040 | loss 0.1655 | valDice 0.2019 | best 0.2409\n",
      "Epoch 041 | loss 0.1179 | valDice 0.2208 | best 0.2409\n",
      "Epoch 042 | loss 0.1127 | valDice 0.2154 | best 0.2409\n",
      "Epoch 043 | loss 0.0965 | valDice 0.1915 | best 0.2409\n",
      "Epoch 044 | loss 0.0955 | valDice 0.1778 | best 0.2409\n",
      "Epoch 045 | loss 0.1017 | valDice 0.2040 | best 0.2409\n",
      "Epoch 046 | loss 0.1164 | valDice 0.2141 | best 0.2409\n",
      "Epoch 047 | loss 0.1216 | valDice 0.2210 | best 0.2409\n",
      "Epoch 048 | loss 0.1417 | valDice 0.2193 | best 0.2409\n",
      "Epoch 049 | loss 0.1335 | valDice 0.2171 | best 0.2409\n",
      "Epoch 050 | loss 0.1381 | valDice 0.2373 | best 0.2409\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def train_epoch(model, loader, opt, scaler, ema=None):\n",
    "    model.train()\n",
    "    total=0.0\n",
    "    for vol, onehot, lab in loader:\n",
    "        vol = vol.to(device, non_blocking=True)\n",
    "        onehot = onehot.to(device, non_blocking=True)\n",
    "        lab = lab.to(device, non_blocking=True)\n",
    "        opt.zero_grad(set_to_none=True)\n",
    "        with torch.cuda.amp.autocast(enabled=AMP):\n",
    "            outs = model(vol)\n",
    "            loss = combined_loss(outs, onehot, lab)\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(opt); scaler.update()\n",
    "        if ema: ema.update(model)\n",
    "        total += loss.item()\n",
    "    return total/len(loader)\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate(model, loader, ema=None):\n",
    "    if ema:\n",
    "        bak = {k: v.detach().clone() for k,v in model.state_dict().items()}\n",
    "        ema.apply_to(model)\n",
    "    model.eval()\n",
    "    ds = []\n",
    "    for vol, _, lab in loader:\n",
    "        vol = vol.to(device, non_blocking=True)\n",
    "        lab = lab.to(device, non_blocking=True)\n",
    "        lg = model(vol)[0]\n",
    "        ds.append(dice_from_logits(lg, lab, 1).item())\n",
    "    if ema:\n",
    "        model.load_state_dict(bak, strict=False)\n",
    "    return float(np.mean(ds)) if ds else 0.0\n",
    "\n",
    "model = SEResUNetPP(IN_CHANNELS, NUM_CLASSES, base=32).to(device)\n",
    "opt = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=AMP)\n",
    "ema = EMA(model, decay=0.999) if USE_EMA else None\n",
    "\n",
    "best=-1.0\n",
    "import csv, time\n",
    "with open(os.path.join(OUT_DIR,\"log.csv\"),\"w\",newline=\"\") as f: csv.writer(f).writerow([\"epoch\",\"train_loss\",\"val_dice\"])\n",
    "\n",
    "for ep in range(1, MAX_EPOCHS+1):\n",
    "    t0=time.time()\n",
    "    tl = train_epoch(model, train_loader, opt, scaler, ema)\n",
    "    vd = validate(model, val_loader, ema)\n",
    "    with open(os.path.join(OUT_DIR,\"log.csv\"),\"a\",newline=\"\") as f: csv.writer(f).writerow([ep, tl, vd])\n",
    "    if vd>best:\n",
    "        best=vd\n",
    "        torch.save({\"epoch\":ep, \"state_dict\":(ema.shadow if ema else model.state_dict()), \"val_dice\":vd},\n",
    "                   os.path.join(OUT_DIR, \"seresunetpp_best.pth\"))\n",
    "    print(f\"Epoch {ep:03d} | loss {tl:.4f} | valDice {vd:.4f} | best {best:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83869258",
   "metadata": {},
   "source": [
    "## Inference: sliding window + Gaussian blending + mirror TTA + Largest Component Post‑Processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a624cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def gaussian_weight(patch):\n",
    "    z,y,x = patch\n",
    "    zz = np.linspace(-1,1,patch[0])[:,None,None]\n",
    "    yy = np.linspace(-1,1,patch[1])[None,:,None]\n",
    "    xx = np.linspace(-1,1,patch[2])[None,None,:]\n",
    "    g = np.exp(-0.5*(zz**2 + yy**2 + xx**2))\n",
    "    return g.astype(np.float32)\n",
    "\n",
    "GAUSS = gaussian_weight(PATCH)\n",
    "\n",
    "def predict_volume(model, img_path, out_path):\n",
    "    img0 = sitk.ReadImage(img_path)\n",
    "    img = sitk_resample_to_spacing(img0, spacing, is_label=False)\n",
    "    vol = sitk.GetArrayFromImage(img).astype(np.float32)\n",
    "    vol = normalize_ct_hu(vol) if MODALITY==\"CT\" else normalize_mri_z(vol, vol!=0)\n",
    "\n",
    "    sz, sy, sx = vol.shape\n",
    "    pz, py, px = PATCH\n",
    "    stz = max(1, int(pz*(1-OVERLAP)))\n",
    "    sty = max(1, int(py*(1-OVERLAP)))\n",
    "    stx = max(1, int(px*(1-OVERLAP)))\n",
    "\n",
    "    prob = np.zeros((NUM_CLASSES, sz, sy, sx), np.float32)\n",
    "    weight = np.zeros((sz, sy, sx), np.float32)\n",
    "\n",
    "    def run(inp):\n",
    "        t = torch.from_numpy(inp[None,None]).to(device)\n",
    "        with torch.no_grad(), torch.cuda.amp.autocast(enabled=AMP):\n",
    "            lg = model(t)[0]\n",
    "            p = torch.softmax(lg, dim=1)[0].cpu().numpy()\n",
    "        return p\n",
    "\n",
    "    for z in range(0, max(1, sz - pz + 1), stz):\n",
    "        for y in range(0, max(1, sy - py + 1), sty):\n",
    "            for x in range(0, max(1, sx - px + 1), stx):\n",
    "                patch = vol[z:z+pz, y:y+py, x:x+px]\n",
    "                pad = [(0, max(0, pz - patch.shape[0])),\n",
    "                       (0, max(0, py - patch.shape[1])),\n",
    "                       (0, max(0, px - patch.shape[2]))]\n",
    "                patch = np.pad(patch, pad, mode=\"edge\")\n",
    "                p = run(patch)\n",
    "                if TTA_MIRROR:\n",
    "                    p = (p\n",
    "                         + np.flip(run(np.flip(patch, 0)), 1)\n",
    "                         + np.flip(run(np.flip(patch, 1)), 2)\n",
    "                         + np.flip(run(np.flip(patch, 2)), 3)) / 4.0\n",
    "                gw = GAUSS[:, :p.shape[1], :p.shape[2]]\n",
    "                p = p * gw[None]\n",
    "                z2 = min(pz, sz - z); y2 = min(py, sy - y); x2 = min(px, sx - x)\n",
    "                prob[:, z:z+z2, y:y+y2, x:x+x2] += p[:, :z2, :y2, :x2]\n",
    "                weight[z:z+z2, y:y+y2, x:x+x2] += gw[:z2, :y2, :x2]\n",
    "\n",
    "    prob /= np.maximum(weight[None], 1e-6)\n",
    "    seg = np.argmax(prob, axis=0).astype(np.uint8)\n",
    "\n",
    "    if POSTPROC_KEEP_LARGEST and NUM_CLASSES>1:\n",
    "        s_img = sitk.GetImageFromArray((seg==1).astype(np.uint8)); s_img.CopyInformation(img)\n",
    "        cc = sitk.ConnectedComponent(s_img)\n",
    "        rel = sitk.RelabelComponent(cc, sortByObjectSize=True)\n",
    "        largest = sitk.BinaryThreshold(rel, 1, 1, 1, 0)\n",
    "        seg = (sitk.GetArrayFromImage(largest)>0).astype(np.uint8)\n",
    "        out = np.zeros_like(sitk.GetArrayFromImage(img), dtype=np.uint8)\n",
    "        out[seg==1] = 1\n",
    "        seg = out\n",
    "\n",
    "    seg_sitk = sitk.GetImageFromArray(seg.astype(np.uint8)); seg_sitk.CopyInformation(img)\n",
    "    back = sitk.Resample(seg_sitk, img0, sitk.Transform(), sitk.sitkNearestNeighbor, 0, sitk.sitkUInt8)\n",
    "    sitk.WriteImage(back, out_path)\n",
    "    print(\"Saved:\", out_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3b88ec",
   "metadata": {},
   "source": [
    "## Example prediction on one test case (edit filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266b2f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_img = f\"{DATA_ROOT}/MSD/{TASK}/imagesTs/la_001.nii.gz\"\n",
    "ckpt = os.path.join(OUT_DIR, \"seresunetpp_best.pth\")\n",
    "out_pred = os.path.join(OUT_DIR, \"la_001_pred_v2.nii.gz\")\n",
    "\n",
    "model = SEResUNetPP(IN_CHANNELS, NUM_CLASSES, base=32).to(device)\n",
    "if os.path.exists(ckpt):\n",
    "    state = torch.load(ckpt, map_location=\"cpu\")\n",
    "    model.load_state_dict(state[\"state_dict\"], strict=False)\n",
    "else:\n",
    "    print(\"Checkpoint not found at\", ckpt, \"- train the model first.\")\n",
    "\n",
    "if os.path.exists(test_img):\n",
    "    predict_volume(model, test_img, out_pred)\n",
    "else:\n",
    "    print(\"Edit 'test_img' with a real imagesTs filename.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4754abd9",
   "metadata": {},
   "source": [
    "## Minimal 3D MAE pretrainer + transfer to seg encoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28175c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MAE3D(nn.Module):\n",
    "    def __init__(self, in_ch=1, emb=96):\n",
    "        super().__init__()\n",
    "        self.enc = nn.Sequential(\n",
    "            nn.Conv3d(in_ch, 32, 3, padding=1), nn.InstanceNorm3d(32, affine=True), nn.LeakyReLU(0.01, True),\n",
    "            nn.Conv3d(32, 64, 3, stride=2, padding=1), nn.InstanceNorm3d(64, affine=True), nn.LeakyReLU(0.01, True),\n",
    "            nn.Conv3d(64, emb, 3, stride=2, padding=1), nn.InstanceNorm3d(emb, affine=True), nn.LeakyReLU(0.01, True),\n",
    "        )\n",
    "        self.dec = nn.Sequential(\n",
    "            nn.ConvTranspose3d(emb, 64, 2, 2), nn.InstanceNorm3d(64, affine=True), nn.LeakyReLU(0.01, True),\n",
    "            nn.ConvTranspose3d(64, 32, 2, 2), nn.InstanceNorm3d(32, affine=True), nn.LeakyReLU(0.01, True),\n",
    "            nn.Conv3d(32, in_ch, 1)\n",
    "        )\n",
    "    def forward(self, x, mask):\n",
    "        z = self.enc(x)\n",
    "        r = self.dec(z)\n",
    "        r = F.interpolate(r, size=x.shape[2:], mode=\"trilinear\", align_corners=False)\n",
    "        return r*mask, x*mask\n",
    "\n",
    "def mae_make_mask(shape, ratio):\n",
    "    B,_,Z,Y,X = shape\n",
    "    m = torch.zeros((B,1,Z,Y,X), device=device)\n",
    "    num = int(Z*Y*X*ratio)\n",
    "    for b in range(B):\n",
    "        idx = torch.randperm(Z*Y*X, device=device)[:num]\n",
    "        m.view(B,1,-1)[b,0,idx] = 1.0\n",
    "    return m\n",
    "\n",
    "class UnlabeledImagesDataset(Dataset):\n",
    "    def __init__(self, images, patch, spacing, modality=\"CT\"):\n",
    "        self.paths = images\n",
    "        self.patch = patch\n",
    "        self.spacing = np.array(spacing, dtype=np.float32)\n",
    "        self.modality = modality\n",
    "    def __len__(self): return len(self.paths)\n",
    "    def _extract(self, v):\n",
    "        Pz,Py,Px = self.patch\n",
    "        Z,Y,X = v.shape\n",
    "        z = np.random.randint(0, max(1, Z-Pz+1))\n",
    "        y = np.random.randint(0, max(1, Y-Py+1))\n",
    "        x = np.random.randint(0, max(1, X-Px+1))\n",
    "        vv = v[z:z+Pz, y:y+Py, x:x+Px]\n",
    "        pad = [(0,max(0,Pz-vv.shape[0])), (0,max(0,Py-vv.shape[1])), (0,max(0,Px-vv.shape[2]))]\n",
    "        return np.pad(vv, pad, mode=\"edge\")\n",
    "    def __getitem__(self, idx):\n",
    "        ip = self.paths[idx]\n",
    "        i_sitk = sitk.ReadImage(ip)\n",
    "        i_rs = sitk_resample_to_spacing(i_sitk, spacing, is_label=False)\n",
    "        vol = sitk.GetArrayFromImage(i_rs).astype(np.float32)\n",
    "        vol = normalize_ct_hu(vol) if self.modality==\"CT\" else normalize_mri_z(vol, vol!=0)\n",
    "        vol = self._extract(vol)\n",
    "        return torch.from_numpy(vol[None, ...])\n",
    "\n",
    "def mae_pretrain(imagesTr_dir, epochs=MAE_EPOCHS, mask_ratio=MAE_MASK_RATIO, save_dir=MAE_OUT):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    imgs = sorted(glob.glob(os.path.join(imagesTr_dir, \"*.nii.gz\")))\n",
    "    ds = UnlabeledImagesDataset(imgs, MAE_PATCH, spacing, MODALITY)\n",
    "    dl = DataLoader(ds, batch_size=2, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "    mae = MAE3D(in_ch=1, emb=96).to(device)\n",
    "    opt = torch.optim.AdamW(mae.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=AMP)\n",
    "    for ep in range(1, epochs+1):\n",
    "        total=0.0\n",
    "        for v in dl:\n",
    "            v = v.to(device, non_blocking=True)\n",
    "            m = mae_make_mask(v.shape, mask_ratio)\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            with torch.cuda.amp.autocast(enabled=AMP):\n",
    "                pr, gt = mae(v, m)\n",
    "                loss = F.l1_loss(pr, gt)\n",
    "            scaler.scale(loss).backward(); scaler.step(opt); scaler.update()\n",
    "            total += loss.item()\n",
    "        print(f\"[MAE] epoch {ep:03d} | loss {total/len(dl):.4f}\")\n",
    "    torch.save({\"encoder\": mae.enc.state_dict()}, os.path.join(save_dir, \"mae_encoder.pth\"))\n",
    "    print(\"Saved MAE encoder to\", os.path.join(save_dir, \"mae_encoder.pth\"))\n",
    "    return os.path.join(save_dir, \"mae_encoder.pth\")\n",
    "\n",
    "def load_mae_encoder_into_seg(model, mae_ckpt_path):\n",
    "    ck = torch.load(mae_ckpt_path, map_location=\"cpu\")[\"encoder\"]\n",
    "    seg_sd = model.state_dict()\n",
    "    mapped=0\n",
    "    for k,v in ck.items():\n",
    "        for tgt in [\"e1\", \"e2\", \"e3\"]:\n",
    "            for sub in [\"conv1.weight\", \"conv1.bias\", \"conv2.weight\", \"conv2.bias\"]:\n",
    "                tk = f\"{tgt}.{sub}\"\n",
    "                if tk in seg_sd and seg_sd[tk].shape == v.shape:\n",
    "                    seg_sd[tk] = v; mapped += 1; break\n",
    "    model.load_state_dict(seg_sd, strict=False)\n",
    "    print(f\"Loaded {mapped} MAE params into segmentation encoder.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
